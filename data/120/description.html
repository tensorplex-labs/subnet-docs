<p>
  Affine is a an incentivized RL environment which pays miners which make
  incremental improvements on a set of tasks (for instance, program abduction or
  coding). The mechanism is sybil-proof (you cant cheat by deploying multiple
  miners), decoy-proof (you cant cheat by packing models into certain
  environments), copy-proof (you cant win by simply stealing the best model),
  overfitting-proof (you can&#39;t cheat by overfitting to the a single
  benchmark).
</p>
<p>
  How does Affine work? Affine validators incentivize miners to submit models to
  Subnet 64 on Bittensor (a.k.a Chutes) where they are inference load balanced
  and publicly available. These models are evaluated on a set of RL-environments
  with validators looking for the model which dominates the pareto frontier --
  namely the model which out competes all other models on all envs (see
  <code>af validator</code>) The network is winners-take-all where miners are
  forced to copy, download and improve the pareto frontier model.
</p>
<p>
  Why affine? Directed incentives for RL have never been achieved. The ability
  to direct intelligence and aggregate the work-effort of a large
  non-permissioned group of individuals on RL tasks will unlock fast advancement
  in intelligence, we intend to commoditize reasoning (intelligence&#39;s
  highest form) and break the intelligence sound barrier.
</p>
